{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import util\n",
    "\n",
    "# set defaults\n",
    "plt.style.use('seaborn-white')   # seaborn custom plot style\n",
    "plt.rc('figure', dpi=100, figsize=(7, 5))   # set default size/resolution\n",
    "plt.rc('font', size=12)   # font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Part 1\n",
    "\n",
    "# Features in Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline\n",
    "\n",
    "* What is a feature?\n",
    "* Feature Engineering.\n",
    "* Designing features for a model: what kind of features you built depends on what kind of data you have: nominal, ordinal etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What have we done so far?\n",
    "\n",
    "* Data assessment and collection:\n",
    "    * The data generating processes and its relationship to observed data.\n",
    "    * Data collection techniques (web-scraping, apis)\n",
    "* Data cleaning and manipulation\n",
    "    * Pandas and Regex\n",
    "* Learned ways of understanding and summarizing data\n",
    "    * Exploratory Data Analysis, visualization, TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Features\n",
    "\n",
    "* A **feature** is a measurable property or characteristic of a phenomenon being observed.\n",
    "* Synonyms: (explanatory) variable, attribute\n",
    "* Examples include:\n",
    "    - a column of a dataset.\n",
    "    - a derived value from a dataset, perhaps using additional information.\n",
    "    \n",
    "We have been creating features to summarize data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Examples of features in SD salary dataset\n",
    "\n",
    "* Salary of employee\n",
    "* Employee salaries, standardized by job status (PT/FT)\n",
    "* Gender/age of employees (derived from SSA names; accurate?)\n",
    "* Job Family associated to a job title (uses text-techniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What makes a good feature?\n",
    "\n",
    "* Fidelity to Data Generating Process (Consistency).\n",
    "* Strongly associated to phenomenon of interest (\"contains information\").\n",
    "* Easily used in standard modeling techniques (e.g. quantitative and scaled).\n",
    "\n",
    "Datasets often come with weak attributes; features may need to be \"engineered\" to convey information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature Engineering\n",
    "\n",
    "* We already engineered features to summarize and understand data.\n",
    "    - smoothing, transformations, ad hoc derived properties of data\n",
    "\n",
    "* What can we do with it?\n",
    "    - Visualization and summarization\n",
    "    - Modeling (prediction; inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predicting child heights\n",
    "\n",
    "* Recall, Francis Galton's obsession with understanding inheritance.\n",
    "* He wanted to predict a child's *height* from their attributes of their parents.\n",
    "    - attributes: family id, father height, mother height, number of children, gender, child height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galton = pd.read_csv('data/galton.csv')\n",
    "galton.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Heights data: quick EDA\n",
    "* What could be done to improve this viz?\n",
    "* Is a linear model suitable for prediction? on which attributes?\n",
    "* There are multiple granularities (what?); is this a problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(galton, figsize=(12,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Attempt #1: Predict child's height using father's height\n",
    "\n",
    "$\\text{predicted height} = w_0 + w_1 \\times \\text{father's height}$\n",
    "\n",
    "1. Plot a scatterplot with a best-fit line and prediction interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='father', y='childHeight', data=galton);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Attempt #1: Predict child's height using father's height\n",
    "\n",
    "Let's do the prediction \"by hand\":\n",
    "\n",
    "* Recall, a prediction is a function $pred$ from the *features* (father height) to the *target* (child height).\n",
    "* The quality of our prediction on the dataset is the *root mean square error* (RMSE): $${\\rm RMSE} =  \\sqrt{\\frac{1}{N}{\\sum_{i=0}^{N}(pred(x_i) - y_i)^2}} $$ where $x_i$ are the father heights, $pred(x_i)$ are the predicted child heights, and $y_i$ are the *actual* child heights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "lm = linregress(galton.father, galton.childHeight)\n",
    "lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_height(father):\n",
    "    return lm.slope * father + lm.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_height(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_height(galton.father).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(np.mean((pred_height(galton.father) - galton.childHeight)**2))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing the predictions\n",
    "* How is our model good? bad?\n",
    "    - Is a linear model appropriate? good?\n",
    "    - How might we make it better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    x='father', y='childHeight', data=galton\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=galton.father,\n",
    "    y=pred_height(galton.father)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Attempt #2: adding features\n",
    "\n",
    "* What if the father is very tall and the mother is short?\n",
    "* Will adding mother's height help our predictions?\n",
    "\n",
    "$\\text{predicted height} = w_0 + w_1 \\times \\text{(father's height)} + w_2 \\times \\text{(mother's height)}$\n",
    "\n",
    "* Try: regression on two variables (mother/father height).\n",
    "    - \"plane of best fit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sklearn\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typical pattern; focus on this later!\n",
    "\n",
    "lr = LinearRegression() # initial linear regression\n",
    "\n",
    "lr.fit(galton[['mother', 'father']], galton.childHeight) # calculate the weights\n",
    "\n",
    "predictions = lr.predict(galton[['mother', 'father']]) # calculate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how good is the prediction?\n",
    "\n",
    "np.sqrt(np.mean(np.abs(predictions - galton.childHeight)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.plot3Dscatter(galton, 'mother', 'father', lr, galton['childHeight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results by father height\n",
    "sns.scatterplot(x=galton['father'], y=galton['childHeight'])\n",
    "sns.scatterplot(x=galton['father'], y=pd.Series(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results by mother height\n",
    "sns.scatterplot(x=galton['mother'], y=galton['childHeight'])\n",
    "sns.scatterplot(x=galton['mother'], y=pd.Series(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Attempt #3: adding gender to the regression\n",
    "\n",
    "* Our previous predictions are constant for a given set of parents.\n",
    "* One would expect male/female children of the same parents to have different heights!\n",
    "* Is it reasonable to add this attribute? Is it known when the prediction is used?\n",
    "\n",
    "First plot a scatterplot of 'father height' vs 'child height' by group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The regression lines (predictions) are very different for male/female\n",
    "sns.lmplot(x='father', y='childHeight', data=galton, hue='gender');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Attempt #3: adding gender to the regression\n",
    "\n",
    "* Problem: gender is *categorical*, while regression requires *quantitative* inputs!\n",
    "    - The table contains two values in the column: male/female\n",
    "* Solution: create a binary column called `gender=male` that:\n",
    "    - is 1 when `gender` has value male, and\n",
    "    - is 0 otherwise\n",
    "    \n",
    "$\\text{predicted height} = w_0 + w_1 \\times \\text{(father's height)} + w_2 \\times \\text{(mother's height)}\n",
    "+ w_3 \\times \\text{(gender=male)}\n",
    "$\n",
    "    \n",
    "This is a simple example of *one-hot encoding*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galton['gender=male'] = (galton.gender == 'male').astype(int)\n",
    "galton.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gender = LinearRegression()\n",
    "lr_gender.fit(galton[['father', 'mother', 'gender=male']], galton.childHeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_gender = lr_gender.predict(galton[['father', 'mother', 'gender=male']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean(np.abs(predictions_gender - galton.childHeight )**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results by father height\n",
    "sns.scatterplot(x=galton['father'], y=galton['childHeight'])\n",
    "sns.scatterplot(x=galton['father'], y=pd.Series(predictions_gender))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing regression with one-hot encoding\n",
    "\n",
    "* One-hot encoding \"pulls the two genders apart\" in the scatterplot, along a 3rd dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The regression lines (predictions) are very different for male/female\n",
    "sns.lmplot(x='father', y='childHeight', data=galton, hue='gender');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gender_2 = LinearRegression()\n",
    "lr_gender_2.fit(galton[['gender=male', 'father']], galton.childHeight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.plot3Dscatter(galton, 'gender=male', 'father', lr_gender_2, galton['childHeight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Part 2\n",
    "\n",
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The goal of feature engineering\n",
    "\n",
    "* Find transformations that effectively transform data into effective quantitative variables\n",
    "\n",
    "* Find functions $\\phi:{\\rm DATA}\\to\\mathbb{R}^d$ where similar points $x,y\\in {\\rm DATA}$ have close images $\\phi(x), \\phi(y)\\in \\mathbb{R}^d$\n",
    "\n",
    "* A \"good\" choice of features depends on many factors:\n",
    "    - data type (quantitative, ordinal, nominal),\n",
    "    - the relationship(s) and association(s) being modeled,\n",
    "    - the model type (e.g. linear models, decision tree models, neural networks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Want to build a linear regression model:\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "    \n",
    "* On a dataset of product review data (X),\n",
    "* To understand the relationship to product ratings (Y).\n",
    "* Using \"plane of best fit\"\n",
    "\n",
    "<img src=\"imgs/plane.jpg\">\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Want to build a linear model\n",
    "\n",
    "* Why can't a linear model be built review data directly?\n",
    "* What needs to happen to build the model?\n",
    "* What are concrete steps to take?\n",
    "\n",
    "|UID|AGE|STATE|HAS_BOUGHT|REVIEW|\\||RATING|\n",
    "|---|---|---|---|---|---|---|\n",
    "|0|32|NY|True|\"Meh.\"|\\||&#10025;&#10025;|\n",
    "|42|50|WA|True|\"Worked out of the box...\"|\\||&#10025;&#10025;&#10025;&#10025;|\n",
    "|57|16|CA|NULL|\"Hella tots lit yo...\"|\\||&#10025;|\n",
    "|...|...|...|...|...|\\||...|\n",
    "|(int)|(int)|(str)|(bool)|(str)|\\||(str)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Basic Transformations: uninformative features\n",
    "\n",
    "`UID` was likely used to join the user information (e.g., `age`, and `state`) with some `Reviews` table.  The `UID` presents several questions:\n",
    "* What is the meaning of the `UID` *number*? \n",
    "* Does the magnitude of the `UID` reveal information about the rating?\n",
    "* Does adding `UID` improve our model?\n",
    "* **Transformation:** drop the feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dropping Features\n",
    "\n",
    "There are certain scenarios where manually dropping features might be helpful:\n",
    "\n",
    "1. when the features **does not to contain information** associated with the prediction task.  \n",
    "2. when the feature is **not available at prediction time.**  For example, the feature might contain information collected after the user entered a rating.  This is a common scenario in time-series analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Basic Transformations: scaling features\n",
    "\n",
    "`AGE` might contain corrupted or 'clumped' data that requires scaling:\n",
    "- **Transformation:** apply binning to discretize the data into quartiles.\n",
    "- **Transformation:** apply non-linear transformation (e.g. log, sqrt).\n",
    "- **Transformation:** normalize/standardize (z-scale; range)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Basic Transformations: ordinal encoding\n",
    "\n",
    "How to encode the `RATING` column as a quantitative variable?\n",
    "* **Transformation:** \"number of &#10025;\" to \"number\".\n",
    "    - Called *ordinal encoding*: map the ordinal values onto the integer, preserving order.\n",
    "* Does this preserve \"distances\" between ratings? (yes).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_values = ['✩', '✩✩', '✩✩✩', '✩✩✩✩', '✩✩✩✩✩']\n",
    "ordinal_enc = {y:x for (x,y) in enumerate(order_values)}\n",
    "ordinal_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.Series(['✩', '✩✩', '✩✩✩', '✩✩', '✩✩✩', '✩', '✩✩✩', '✩✩✩✩', '✩✩✩✩✩'], name='RATING')\n",
    "ratings.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings\n",
    "ratings.replace(ordinal_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Basic Transformations: one-hot encoding\n",
    "\n",
    "How to encode the `STATE` column as a quantitative variable?\n",
    "- How do we make STATE into a meaningful number?\n",
    "- Ordinal Encoding? AL=1,...,WY=50? (No!)\n",
    "- **Transformation:** 50 binary variables: `is_AL`,...,`is_WY`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nominal feature encoding: One hot encoding\n",
    "\n",
    "* Transform categorical features into many binary features.\n",
    "* Given a column `col` with values `A1,A2,...A_N`, define the following quantitative binary columns:\n",
    "\n",
    "$$\\phi_i(x) = \\left\\{\\begin{array}{ll}1 & {\\rm if\\ } x = A_i \\\\ 0 &  {\\rm if\\ } x\\neq A_i \\\\ \\end{array}\\right. $$\n",
    "\n",
    "* *Also called:* dummy encoding; indicator variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: one hot encoding States\n",
    "\n",
    "* A column containing US states transforms into 50 feature columns\n",
    "* e.g. `phi_CA(x) = 1 if x == 'CA' else 0`\n",
    "* Oftentimes, many of these columns will be *largely* 0.\n",
    "\n",
    "<img src=\"imgs/image_4.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([['NY'], ['WA'], ['CA'], ['NY'], ['OR']], columns=['STATE'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = df.STATE.unique()\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row by row\n",
    "\n",
    "df['STATE'].apply(lambda x: pd.Series(x == states, index=states, dtype=int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Part 3\n",
    "\n",
    "# Features and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Features and Models\n",
    "\n",
    "Feature engineering transforms data into quantitative attributes, such that \n",
    "* similar observations are close in the feature space.\n",
    "* the features are presented in a way usable for the desired model.\n",
    "\n",
    "\n",
    "The quality of a feature is measured by the question being asked and the appropriateness for model used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The missing step: data to models\n",
    "\n",
    "* Modeling techniques typically require *quantitative* input.\n",
    "* Models require (strong) relationships between X and Y.\n",
    "\n",
    "<img src=\"imgs/image_1.png\">\n",
    "\n",
    "There is work to be done transforming data into effective features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to Modeling\n",
    "\n",
    "* Data Generating Process: The real-word phenomena from which data are collected.\n",
    "    - *Example:* Every year, city employees gain/lose employment, earning a salary.\n",
    "    - Can't observe this process directly.\n",
    "* Model: a theory about the Data Generating Process:\n",
    "    - *Example:* If an employee is X years older than average, then they will make significantly more in salary. \n",
    "    - How is this model created?\n",
    "* Fit Model: a model specified to a particular set of observations (dataset).\n",
    "    - *Example:* If an employee is 5 years older than average, they will make significantly more in salary.\n",
    "    - How is this estimate determined? What makes it \"good\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What questions can models answer?\n",
    "\n",
    "* Questions of *Prediction*: Given what I've seen, what is the most likely value I'll see in the future?\n",
    "    - Prediction forecasts the values of the data coming from the data generating process.\n",
    "* Questions of *(Statistical) Inference*: How likely is what I observed representative of the broader picture?\n",
    "    - Statistical Inference draws conclusions (with confidence) about the structure of the data generating process (*population*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Statistical Model: Inference\n",
    "\n",
    "* A **statistical model** is a quantitative relationship between properties in observed data.\n",
    "* A *statistical model* is a function $S:X\\to\\mathbb{R}^n$ that measures properties of $X$.\n",
    "* **Example:** Is there a linear relationship between the heights of children and the height of their biological mother?\n",
    "    * $X = \\texttt{mother_height} = \\mathbb{R}$\n",
    "    * $Y = \\texttt{child_height} = \\mathbb{R}$\n",
    "    * $S$ is the correlation coefficient\n",
    "    \n",
    "Inference results in interpreting properties of the DGP from the parameters of the model (correlation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prediction Model: Regression\n",
    "\n",
    "* **Regression Models** attempt to predict the most likely quantitative value associated to an observation (feature).\n",
    "* A *regressor* is a function $R:X\\to \\mathbb{R}$ that predicts the value $y\\in \\mathbb{R}$ of an observation $x\\in X$.\n",
    "* **Example:** Given the heights of a child's parents, what is the height of their child?\n",
    "    * $X = (\\texttt{father_height, mother_height}) = \\mathbb{R}^2$\n",
    "    * $Y = \\texttt{child_height} = \\mathbb{R}$\n",
    "    * $C$ predicts child heights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prediction Model: Classification\n",
    "\n",
    "* **Classification Models** attempt to predict the most likely *class* associated to an observation (feature).\n",
    "    - The *type* or *class* is a *nominal* attribute (e.g. 'YES' or 'NO').\n",
    "\n",
    "* A *classifier* is a function $C:X\\to Y$ that predicts whether an observation $x\\in X$ belongs to class $y\\in Y$.\n",
    "\n",
    "* **Example:** Given product purchase attributes (item, price, age, state), can one predict whether the person was satisfied with their purchase?\n",
    "    - $X = \\{(\\texttt{item, price, age, state})\\}$\n",
    "    - $Y = \\{\\texttt{'SATISFIED'}, \\texttt{'NOT SATISFIED'}\\}$\n",
    "    - $C$ predicts product satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Part 4\n",
    "\n",
    "# Example: Restaurant Tips "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "* Data: collected by a single waiter over a month.\n",
    "* Why build a model?\n",
    "    - Predict which tables will tip the highest? (Optimize your service)\n",
    "    - Predict a waiter's income for the year. (Regression)\n",
    "    - Understand relationship between diners and tips. (Inference)\n",
    "    \n",
    "\n",
    "*Can we predict tip amounts from the total bill? (Prediction; Regression)*\n",
    "    \n",
    "Credit: Joseph Gonzalez, DS100 (UC Berkeley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tips = sns.load_dataset('tips')\n",
    "print('number of records: ', len(tips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EDA\n",
    "\n",
    "* How does the total bill differ from tip amount?\n",
    "* Are there outliers in the tips?\n",
    "* What do tips \"look like\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "sns.distplot(tips.total_bill, rug=True, ax=axes[0])\n",
    "axes[0].set_xlabel('total bill')\n",
    "\n",
    "sns.distplot(tips.tip, rug=True, ax=axes[1])\n",
    "axes[1].set_xlabel('tip in dollars')\n",
    "\n",
    "fig.suptitle('Understanding tips');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Observations:\n",
    "|Total Bill|Tip Amount|\n",
    "|---|---|\n",
    "|Right skewed|Right skewed|\n",
    "|Mode around \\$15|Mean around 3|\n",
    "|Mean around \\$20|Possibly bimodal (?)|\n",
    "|No large bills|Large outliers (?)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### An initial model: Constant\n",
    "\n",
    "Suppose our model assumes every tip is given by a constant dollar amount:\n",
    "\n",
    "$$\\texttt{tip} = \\theta^* \\quad\\leftarrow (^* {\\rm \\: means\\: true\\: parameter\\: determined\\: by\\: universe})$$\n",
    "\n",
    "* Model: There is a single tip amount $\\theta^*$ that all customers pay.\n",
    "    - Correct? No! What are reasons that other amount may be present in data?\n",
    "    - Useful? Perhaps. An estimate $\\theta^*$ allows us to predict future tips. Have to start somewhere!\n",
    "    \n",
    "* The parameter $\\theta^*$ is determined by the universe (data generating process)\n",
    "    - We can't observe the parameter; we need to *estimate $\\theta^*$ from the data*.\n",
    "    - Could be different for a different restaurant!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## All models are wrong...\n",
    "\n",
    "\"...but some are useful.\"\n",
    "\n",
    "> \"Since all models are wrong the scientist cannot obtain a \"correct\" one by excessive elaboration. On the contrary following William of Occam he should **seek an economical description of natural phenomena**. Just as the ability to devise simple but evocative models is the signature of the great scientist so overelaboration and overparameterization is often the mark of mediocrity.\"\n",
    "\n",
    "> \"Since all models are wrong the scientist must be alert to what is importantly wrong. It is inappropriate to be concerned about mice when there are tigers abroad.\"\n",
    "\n",
    "~ George Box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to estimate the parameter $\\theta^*$\n",
    "\n",
    "* Use *prior knowledge*: a coffee shop? \\\\$1? a diner \\\\$5? Even bill amounts?\n",
    "* Use the data!\n",
    "    - Calculate use the mean? median? mode?\n",
    "* Which is the best estimate? which model 'fits' the data best?\n",
    "    - Depends on the goal and the problem\n",
    "    - Should measure how \"close\" the predictions are to the true values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Constant model attempt\n",
    "\n",
    "* Constant model: assume every tip is a constant value -- the mean tip of ~\\\\$3.\n",
    "* How good is this model? How wrong are its predictions?\n",
    "* Measure error using a **loss function**:\n",
    "    - Root Mean Square Error: $${\\rm RMSE} = \\sqrt{\\frac{1}{N}\\sum(R(x_i) - y_i)^2}$$\n",
    "    - Mean Absolute Error: $${\\rm MAE} = \\frac{1}{N}\\sum|R(x_i) - y_i|$$\n",
    "\n",
    "Where $x_i$ are the observations, $y_i$ are the true values, and $R$ is the prediction function (regressor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Constant guess amount\n",
    "mean_tip = tips.tip.mean()\n",
    "mean_tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "diffs = (mean_tip - tips.tip)\n",
    "preds = tips[['total_bill', 'tip']].assign(\n",
    "    prediction=mean_tip,\n",
    "    error=lambda x:(x['tip'] - x['prediction'])\n",
    ")\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# MAE -- in dollar amounts!\n",
    "preds.error.abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE -- in dollar amounts!\n",
    "(preds.error**2).mean()**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Was there a better choice than using the (historical) mean tip?\n",
    "\n",
    "If we want the model that has the smallest RMSE possible:\n",
    "\n",
    "$${\\rm RMSE} = \\sqrt{\\frac{1}{N}\\sum(\\hat\\theta - t_i)^2}$$\n",
    "\n",
    "To minimize, can ignore the square root:\n",
    "\n",
    "$$RMSE = \\frac{1}{N}\\sum_{i=1}^{N}(\\hat\\theta - t_i)^2$$\n",
    "\n",
    "Set derivative of the RMSE to zero:\n",
    "\n",
    "$$0 = \\frac{2}{N}\\sum_{i=1}^{N}(\\hat\\theta - t_i) = \\frac{2N\\hat\\theta}{N} - \\frac{2}{N}\\sum_{i=1}^{N}t_i$$\n",
    "\n",
    "Solving for $\\hat\\theta$ gives:\n",
    "\n",
    "$$\\hat\\theta = \\frac{1}{N}\\sum_{i=1}^{N}t_i$$\n",
    "\n",
    "So our model parameter was *best* choice (for our chosen loss function, RMSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A Derived Feature: Can it help our model?\n",
    "\n",
    "* A *derived feature* might help explain tip amounts: $$\\texttt{pct_tip} = \\frac{\\texttt{tip}}{\\texttt{total_bill}}$$\n",
    "\n",
    "* Example of quantitative scaling!\n",
    "* Natural representation of tips: in US, custom is to tip a percentage.\n",
    "* What is the data quality assessment of this quantitative transformation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = tips.assign(pct_tip=(tips['tip'] / tips['total_bill']))\n",
    "sns.distplot(tips['pct_tip'], rug=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A new constant model: derived features\n",
    "\n",
    "Suppose our model assumes every tip is given by a constant `pct_tip`:\n",
    "\n",
    "$$\\texttt{pct_tip} = \\theta^* \\quad\\leftarrow (^* {\\rm \\: Means\\: true\\: parameter\\: determined\\: by\\: universe})$$\n",
    "\n",
    "* Model: There is a percent tip $\\theta^*$ that all customers pay.\n",
    "    - Correct? No! What are reasons that other percentages may be present in data?\n",
    "    - Useful? Perhaps. A good estimate $\\theta^*$ could allows us to predict future tips.\n",
    "    \n",
    "* The parameter $\\theta^*$ is determined by the universe (data generating process)\n",
    "    - We can't observe the parameter; we need to *estimate $\\theta^*$ from the data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "sns.distplot(tips.tip, rug=True, ax=axes[0])\n",
    "axes[0].set_xlabel('tip in dollars')\n",
    "\n",
    "sns.distplot(tips['pct_tip'], rug=True, ax=axes[1])\n",
    "axes[1].set_xlabel('tip percentage')\n",
    "\n",
    "fig.suptitle('Understanding tips');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to estimate the parameter $\\theta^*$\n",
    "\n",
    "* Use *prior knowledge*: e.g. 15%\n",
    "* Use the data!\n",
    "    - Calculate the percentage from a random selection of tables? Use the mean? median? mode?\n",
    "* Which is the best estimate? which model 'fits' the data best?\n",
    "    - Depends on the goal and the problem\n",
    "    - Should measure how \"close\" the predictions are to the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = (tips.total_bill * 0.15) - tips.tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE\n",
    "diffs.abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "(diffs**2).mean()**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conclusion: constant model with derived feature\n",
    "\n",
    "* Tipping 15% has better RMSE than the *best* constant (dollar amount) model!\n",
    "* The error is still close to a dollar per tip, on average!\n",
    "    - The average tip is only 3 dollars...\n",
    "* Can we do better? new features? a more complex model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Attempt #3: linear model\n",
    "\n",
    "* Build a model with no derived features, but more complex than a constant model.\n",
    "* Model: tips are made according to a linear function the entire total bill:\n",
    "    - The model parameter $\\theta^*$ consists of the *slope* and *y-intercept*.\n",
    "    - Linear regression model fits the *best* linear predictor for RMSE.\n",
    "* To be appropriate, a \"linear assumption\" must hold!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=tips, x='total_bill', y='tip');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "lr = linregress(tips.total_bill, tips.tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression coefficients\n",
    "m, b = lr.slope, lr.intercept\n",
    "m, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = m * tips.total_bill + b\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "errors = preds - tips.tip\n",
    "(errors ** 2).mean() ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conclusion: Linear model\n",
    "\n",
    "* Best linear predictor (for RMSE)! Why is it necessarily better than our \"constant percentage model\"?\n",
    "* Tip ~\\\\$1 upfront (intercept), then at ~10.5% for every dollar thereafter (slope).\n",
    "* But is a linear model the *best model choice*?\n",
    "    - This is an inference problem (what does the data look like 'in general'?)\n",
    "    - Use $R^2$ for 'goodness of fit'\n",
    "    - Beware of heteroskedasticity, multicolinearity, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Adding features to predict tips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "tips = sns.load_dataset('tips')\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One hot encoding categorical variables\n",
    "* Are all of these variable nominal?\n",
    "* Do we have redundant variables we can drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['sex', 'smoker', 'day', 'time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tips.copy().loc[:,['total_bill', 'size']]\n",
    "for c in categorical_cols:\n",
    "    for val in tips[c].unique():\n",
    "        features['%s=%s' %(c, val)] = (tips[c] == val).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(features, tips.tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error is a few cents less than previous\n",
    "np.sqrt(np.mean((lr.predict(features) - tips.tip)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lr.predict(features)\n",
    "a = pd.concat([tips.total_bill, pd.Series(preds).rename('prediction'), tips.tip], axis=1)\n",
    "ax = plt.subplot()\n",
    "a.plot(kind='scatter', x='total_bill', y='prediction', ax=ax, c='b')\n",
    "a.plot(kind='scatter', x='total_bill', y='tip', ax=ax, c='r', alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transformations of quantitative features\n",
    "* Transforming quantitative features can enhance 'hidden trends' in data.\n",
    "* Examples:\n",
    "    - Growth rates scaled to linear trends (e.g. log, sqrt)\n",
    "    - Periodic trends separated from growth (e.g. sin)\n",
    "    - Group-wise scaling\n",
    "    - Interactions between variables (e.g. polynomial encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: de-trending periodic sales\n",
    "\n",
    "* Daily sales volume from an e-commerce product\n",
    "* Like to predict future sales, based on current trends:\n",
    "    - What seasonality (periodicity) is present?\n",
    "    - What is long-run growth? (linear? quadratic? exponential?)\n",
    "    - Can you guess a feature that models these properties?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/sinusoidal.csv').sort_values(by='day').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='scatter', x='day', y='units sold', title='daily sales volume');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: de-trending periodic sales\n",
    "\n",
    "* Periodic sales by week (7-day period).\n",
    "* Sales have ~10x difference between low and high (amplitude).\n",
    "* Sales is approximately 'linear growth + periodic term'\n",
    "* Feature:\n",
    "$$ \\phi(x) = x + 5\\sin\\left(\\frac{2\\pi\\cdot x}{7}\\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detrend(day):\n",
    "    '''\n",
    "    Periodic sales volume by the week.\n",
    "    Sales sees ~10x weekly difference between low and high.\n",
    "    '''\n",
    "    return day +  5 * np.sin(2 * np.pi * day / 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['detrend'] = detrend(df['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('day').sort_index().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature space vs target space\n",
    "# linear relationship!\n",
    "df[['units sold', 'detrend']].plot(kind='scatter', x='detrend', y='units sold');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=df, x='day', y='units sold')\n",
    "sns.residplot(data=df, x='day', y='units sold', color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=df, x='detrend', y='units sold')\n",
    "sns.residplot(data=df, x='detrend', y='units sold', color='r')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
