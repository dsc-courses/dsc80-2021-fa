{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# set defaults\n",
    "plt.style.use('seaborn-white')   # seaborn custom plot style\n",
    "plt.rc('figure', dpi=100, figsize=(7, 5))   # set default size/resolution\n",
    "plt.rc('font', size=12)   # font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "flips1 = pd.DataFrame(np.random.choice(['H', 'T'], p=[0.55, 0.45], size=(114,1)), columns=['result'])\n",
    "flips2 = pd.DataFrame(np.random.choice(['H', 'T'], p=[0.50, 0.50], size=(87,1)), columns=['result'])\n",
    "flips3 = pd.DataFrame(np.random.choice(['H', 'T'], p=[0.7, 0.3], size=(12,1)), columns=['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lecture 4 - Part 1\n",
    "\n",
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Answering Question with Confidence\n",
    "\n",
    "* Now that out data is cleaned, and\n",
    "* We're confident its faithful to the data generating process (DGP)...\n",
    "* How do we ask questions and draw conclusions about the DGP from the data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Is this coin fair?\n",
    "\n",
    "* Given a dataset of coin flips; was the coin a fair coin?\n",
    "* Do we 'trust' the dataset?\n",
    "* What is fair? \n",
    "    - Ideally: 50H:50T? but does this ever happen?\n",
    "    - What is a 'reasonable' deviation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flips1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flips1['result'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is a reasonable deviation in observed data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize that to get the empirical distribution!\n",
    "flips1['result'].value_counts(normalize=True).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hypothesis Testing\n",
    "* Understand what 'reasonable' deviation is from 'expected.'\n",
    "* Assess how much the *observed* data deviates from 'expected' -- is it reasonable?\n",
    "\n",
    "These concepts need to be *quantified* with measurements!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Measuring the fairness of a coin? Making it quantified\n",
    "\n",
    "Suppose a coin is flipped $N$ times, $N_H$ of which were heads. For each measurement, what is the value you expect from $N$ flips of a fair coin?\n",
    "\n",
    "* $N_H$, (number of heads)\n",
    "* $\\frac{N_H}{N}$, (proportion of heads)\n",
    "* $N_H - \\frac{N}{2}$, (difference from expected number of heads)\n",
    "* $|N_H - \\frac{N}{2}|$, (absolute difference from expected number of heads)\n",
    "\n",
    "Each of these is a **test statistic**, which measures information that answers the questions we're trying to answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the fairness of a coin? 114 flips fair vs observed\n",
    "\n",
    "Suppose a coin is flipped $N$ times, $N_H$ of which were heads. For each measurement, what is the value you expect from $N$ flips of a fair coin?\n",
    "\n",
    "* $N_H$\n",
    "    - expected: 57 (number of heads)\n",
    "    - actual: 68\n",
    "* $\\frac{N_H}{N}$ (proportion that are heads)\n",
    "    - expected: 0.5\n",
    "    - actual: 0.59\n",
    "* $N_H - \\frac{N}{2}$ (difference from expected number of heads)\n",
    "    - expected: 0\n",
    "    - actual: 11\n",
    "* $|N_H - \\frac{N}{2}|$ (absolute difference from expected number of heads)\n",
    "    - expected: 0\n",
    "    - actual: 11 \n",
    "\n",
    "Each of these is a **test statistic**, which measures information that answers the questions we're trying to answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Is this coin fair?\n",
    "\n",
    "- We can calculate (or compute) the probability of seeing what we saw under the assumption that the coin is fair.\n",
    "- If the probability is very small, is seems unlikely that we'd just be that unlucky.\n",
    "- We then \"reject\" the hypothesis that the coin is fair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Is this coin fair?\n",
    "\n",
    "1. Use the 'number of heads' as the test-statistic\n",
    "2. Calculate the observed value for this statistic\n",
    "3. Simulate values of the test statistic a 'fair coin'\n",
    "4. Use this simulation to estimate probability of observing what we observed.\n",
    "5. Ask: was the observed value likely to come from a 'fair coin'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flipped a coin 114 times\n",
    "flips1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resulted in 68 heads, is this too high? or normal fluctuations?\n",
    "obs = (flips1['result'] == 'H').sum()\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of simulations\n",
    "N = 10000\n",
    "\n",
    "# flip a coin 114 times; do this N  times.\n",
    "results = []\n",
    "for _ in range(N):\n",
    "    simulation = np.random.choice(['H', 'T'], p = [0.5, 0.5], size = 114)\n",
    "    sim_heads = (simulation == 'H').sum()  # test stastistic\n",
    "    results.append(sim_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling distribution \n",
    "pd.Series(results).plot(kind='hist', density=True, title='number of heads from flipping a fair coin 114 times');\n",
    "plt.scatter([obs], [0], s=25, c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Do you think the coin was fair?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 / 100 times you would draw the wrong conclusion!\n",
    "(pd.Series(results) >= obs).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hypothesis Test: assessing the fairness of a coin\n",
    "\n",
    "* Decide on a measurement to assess the question being asked of the data: number of heads.\n",
    "    - This is called a **test statistic**\n",
    "* Decide what 'expected' behavior is: 'a fair coin tossed 114 times results in ~57 Heads.'\n",
    "    - This is called a **probability** model; \n",
    "    - Basis for understanding the (reasonable) deviation from expected \n",
    "    - It can be sampled.\n",
    "* Simulate from the probability model and assess the likelihood the observed data is explained by it.\n",
    "    - What is the likelihood you make a mistake asserting the observed data is *not explained* by it?\n",
    "    - This is the **p-value**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(results).plot(kind='hist', density=True, title='number of heads from flipping a fair coin 114 times');\n",
    "plt.scatter([obs], [0], s=25, c='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 / 100 times, you would draw the wrong conclusion!\n",
    "(pd.Series(results) >= obs).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Aside: speeding up the simulation\n",
    "\n",
    "- How long does 100,000 trials take? (Flip 114 coins 100,000 times)\n",
    "- How long would it take for 1 million?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# number of simulations\n",
    "N = 100_000\n",
    "\n",
    "# flip a coin 114 times; do this N  times.\n",
    "results = []\n",
    "for _ in range(N):\n",
    "    simulation = np.random.choice(['H', 'T'], p = [0.5, 0.5], size = 114)\n",
    "    sim_heads = (simulation == 'H').sum()  # test stastistic\n",
    "    results.append(sim_heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Aside: Speeding things up\n",
    "\n",
    "* Instead of `H/T` use `1/0`\n",
    "* Instead of a loop, use numpy (not always easy/possible!)\n",
    "    - many of numpy's random number generators accept a *size* parameter\n",
    "    - can generate a random 2d array of independent entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flips1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flips_fast = flips1.replace({'H': 1, 'T': 0})\n",
    "flips_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip 114 coins N times\n",
    "np.random.choice([1, 0], p=[0.5, 0.5], size=(N, 114))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# number of simulations\n",
    "N = 100_000\n",
    "\n",
    "# flip a coin 114 times; do this N  times.\n",
    "simulations = pd.DataFrame(np.random.choice([1, 0], p=[0.5, 0.5], size=(N, 114)))\n",
    "\n",
    "# compute test statistics\n",
    "test_stats = simulations.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the sampling distribution\n",
    "test_stats.plot(kind='hist', density=True, title='number of heads from flipping a fair coin 114 times');\n",
    "plt.scatter([obs], [0], s=25, c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hypothesis testing\n",
    "\n",
    "Faced with a question about the data raised by an observation...\n",
    "1. Carefully pose the question as a testable \"yes or no\" hypothesis.\n",
    "2. Decide on a statistic that helps differentiate between instances that would affirm or reject the hypothesis.\n",
    "3. Create a probability model for the data generating process that reflects the \"known behavior\" of the process.\n",
    "4. Simulate the data generating process using this probability model (the 'Null Hypothesis').\n",
    "5. Assess if the observation is consistent with the simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Part 2\n",
    "\n",
    "# Example: Jury Selection in Alameda County\n",
    "\n",
    "<img src=\"imgs/image_0.png\" width=\"75%\">\n",
    "\n",
    "See example from [DSC 10](https://www.inferentialthinking.com/chapters/11/2/Multiple_Categories.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Jury Panels\n",
    "\n",
    "<img src=\"imgs/image_1.png\">\n",
    "\n",
    "Section 197 of California's Code of Civil Procedure says, \n",
    "> \"All persons selected for jury service shall be selected at random, from a source or sources inclusive of a representative cross section of the population of the area served by the court.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ACLU study:\n",
    "* ACLU studied the ethnic compisition of jury panels in 11 felony trials in Alameda county between 2009 and 2010.\n",
    "* Total number of people reporting for jury duty: 1453\n",
    "* Compared to demographics of the county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jury = pd.DataFrame([\n",
    "    ['Asian', 0.15, 0.26],\n",
    "    ['Black', 0.18, 0.08],\n",
    "    ['Latino', 0.12, 0.08],\n",
    "    ['White', 0.54, 0.54],\n",
    "    ['Other', 0.01, 0.04]\n",
    "], columns='Ethnicity,Eligible,Panels'.split(',')).set_index('Ethnicity')\n",
    "\n",
    "jury"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Are the differences in representation meaningful?\n",
    "* Model: The people on the jury panels were selected at random from the eligible population\n",
    "    - Alternative viewpoint: no, they weren't.\n",
    "* Observed: Empirical distribution of panels\n",
    "* Statistic: similarity to the \"distribution of eligible jurors\"\n",
    "    - Distance between distributions? TVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "title='distributions of ethnicity on jury panels'\n",
    "jury.plot(kind='barh', title=title);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variation_distance(dist1, dist2):\n",
    "    '''Given two empirical distributions, \n",
    "    both sorted with same categories, calculates the TVD'''\n",
    "    return np.sum(np.abs(dist1 - dist2)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is this large? small? \n",
    "# sample from the model to understand the variation!\n",
    "observed = total_variation_distance(jury['Eligible'], jury['Panels'])\n",
    "observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simulate drawing jury panels\n",
    "* Model: Draw a random panel from \"eligible\" distribution\n",
    "* Statistic: TVD between random panel and eligible\n",
    "* Repeat and compare to observed statistic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jury.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jury.Eligible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 1453 jurors from eligible: sample a jury pool\n",
    "\n",
    "draw = np.random.choice(jury.index, p=jury['Eligible'], size=1453)\n",
    "rand_panel_props = pd.Series(draw).value_counts(normalize=True).rename('random panel')\n",
    "rand_panel_props.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_samp = jury.assign(random_panel=rand_panel_props)\n",
    "with_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_samp.plot(kind='barh', title='empirical distribution of panels');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_variation_distance(with_samp['random_panel'], with_samp['Eligible'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Put together the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvds = []\n",
    "\n",
    "for i in np.arange(1000):\n",
    "    draw = np.random.choice(jury.index, p=jury['Eligible'], size=1453)\n",
    "    rand_panel_props = pd.Series(draw).value_counts(normalize=True).rename('random_panel')\n",
    "    new_tvd = total_variation_distance(rand_panel_props, jury['Eligible'])\n",
    "    tvds.append(new_tvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "observed_tvd = total_variation_distance(jury['Panels'], jury['Eligible'])\n",
    "\n",
    "pd.Series(tvds).hist(bins = 20)\n",
    "plt.scatter(observed_tvd, 0, color='red', s=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to speed up the simulation?\n",
    "\n",
    "* Get rid of the loop!\n",
    "* Use `np.random.multinomial`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rndm = np.random.multinomial(1453, jury['Eligible'], size=1000)\n",
    "rndm = rndm / 1453 # normalize the counts\n",
    "rndm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to vectorizize the TVD to apply it row-wise \n",
    "tvds = np.sum(np.abs(rndm - jury['Eligible'].values), axis=1) / 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_tvd = total_variation_distance(jury['Panels'], jury['Eligible'])\n",
    "\n",
    "pd.Series(tvds).hist(bins = 20)\n",
    "plt.scatter(observed_tvd, 0, color='red', s=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Are the jury panels representative?\n",
    "* Likely not! The random samples are not like the observed panels.\n",
    "* This doesn't say *why* the distributions are different!\n",
    "    - Juries drawn from voter rolls and DMV.\n",
    "    - The county rarely follows up on failures to report.\n",
    "    - [Building the jury table is complicated](https://www.inferentialthinking.com/chapters/11/2/Multiple_Categories.html)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary of the method\n",
    "\n",
    "To assess whether an \"observed sample\" was drawn randomly from a known categorical distribution:\n",
    "* Use TVD as the statistic because it measures the distance between categorical distributions\n",
    "* Sample at random from the population and compute the TVD of the random sample and known distribution to get an idea for what reasonable deviation from eligible pool would look like; repeat numerous times\n",
    "* Compare:\n",
    "    - Empirical distribution of simulated TVDs\n",
    "    - Actual TVD from the sample in the study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Intermission\n",
    "\n",
    "# Command Line Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Command Line Tips\n",
    "\n",
    "- The command line can be disorienting, at first.\n",
    "- But there are some things to make it more comfortable:\n",
    "    0. Use tab completion!\n",
    "    1. Use `--help` to get help.\n",
    "    2. Install the `fish` shell (the default is `bash`).\n",
    "    3. Use keyboard shortcuts:\n",
    "        - `ctrl-a` to move to front of line\n",
    "        - `ctrl-e` moves to end\n",
    "        - `alt-b` moves back a word (I remap to alt-left)\n",
    "        - `ctrl-u` deletes to front of line\n",
    "        - `ctrl-w` deletes back a word\n",
    "        - `<up>` recalls previous command\n",
    "        - `<ctrl-r>` initiates search for previous command\n",
    "    4. Consider installing `lsd` for file listing\n",
    "    5. Use `open` to open a file in default app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Part 3\n",
    "\n",
    "# Decisions and Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Incomplete Information\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "    \n",
    "* Want to Choose between two views of the world, based on data in a sample.\n",
    "* It's not always clear whether the data are consistent with one view or the other.\n",
    "* Random samples can turn out quite extreme. It is unlikely, but possible.\n",
    "* *\"Is this jury panel representative of the county?\"*\n",
    "\n",
    "<img src=\"imgs/jury_diversity.jpg\" width=\"50%\"/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Testing Hypotheses\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "* A test chooses between two views of how data were generated\n",
    "* The views are called **hypotheses**\n",
    "* The test picks the hypothesis that is better supported by the observed data\n",
    "* *\"the juries panels are / are not representative of the county.\"*\n",
    "\n",
    "<img src=\"imgs/jury_diversity.jpg\" width=\"50%\"/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Null and Alternative\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "* The method only works if we can simulate data under one of the hypotheses.\n",
    "* **Null hypothesis**\n",
    "    - A well defined probability model about how the data were generated\n",
    "    - We can **simulate data** under the assumptions of this model – “under the null hypothesis”\n",
    "* **Alternative hypothesis**\n",
    "    - A different view about the origin of the data\n",
    "\n",
    "<img src=\"imgs/image_2.png\" width=\"50%\"/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test Statistic\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "    \n",
    "* The statistic that we choose to simulate, to decide between the two hypotheses\n",
    "* What values of the statistic will make us lean towards the null hypothesis?\n",
    "* What values will make us lean towards the alternative?\n",
    "\n",
    "<img src=\"imgs/jury_tvd.png\" width=\"100%\">\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prediction Under the Null Hypothesis\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "* Simulate the test statistic under the null hypothesis; draw the histogram of the simulated values\n",
    "* This displays the **empirical distribution of the statistic under the null hypothesis**\n",
    "* It shows all the likely values of the statistic\n",
    "* The probabilities are approximate, because we can't generate all the possible random samples.\n",
    "\n",
    "\n",
    "<img src=\"imgs/null_distribution.png\" width=\"75%\">\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusion of the Test\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "* Resolving the choice between null and alternative hypotheses\n",
    "* Compare the **observed test statistic** and the empirical distribution under the null hypothesis.\n",
    "* If the observed value is **not consistent** with the distribution, then the test favors the alternative – “rejects the null hypothesis”\n",
    "\n",
    "<img src=\"imgs/conclusion.png\" width=\"100%\">\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Examples of Null hypothesis\n",
    "\n",
    "Often (but not always) the null hypothesis states there is no association or difference between variables or subpopulations. Like so, some typical null hypotheses are:\n",
    "\n",
    "* The average income for men is similar to that for women \n",
    "* Nationality is (perfectly) unrelated to music preference\n",
    "* The average population income was equal over 2012 through 2016\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Example of Alternative hypothesis\n",
    "\n",
    "Hypothesis that sample observations are influenced by some non-random cause (unlike Null Hypothesis).\n",
    "\n",
    "\n",
    "About 10% of the human population is left-handed. Suppose Aaron speculates that students in his class are more likely to be left-handed than people found in the general population.  \n",
    "\n",
    "\n",
    "**Null Hypothesis:** Students in Aaron's class are no more likely to be left-handed than people in the general population.\n",
    "\n",
    "**Alternative Hypothesis:** Students in Aaron's class are more likely to be left-handed than people in the general population.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Signed vs Unsigned Test Statistics\n",
    "\n",
    "- Think back to coin flipping example.\n",
    "- As test stat, we could've picked:\n",
    "    - Difference between actual proportion of H and 0.5: $p - 0.5$\n",
    "    - *Absolute* difference between actual proportion and 0.5: $|p - 0.5|$\n",
    "- When to use which?\n",
    "- Depends on the *alternative* hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unsigned Test Statistics\n",
    "\n",
    "- An unsigned test statistic (like $|p - 0.5|$) only measures *how different* the observed was from the expected.\n",
    "- It doesn't say whether the observed was higher or lower than expected.\n",
    "- Useful for testing alternative hypothesis: The coin is not fair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signed Test Statistics\n",
    "\n",
    "- A signed test statistic (like $p - 0.5$) does say whether observed was higher or lower.\n",
    "- Useful for testing alternative: \"The coin is biased towards heads\" or \"The coin is biased towards tails\"\n",
    "- Convention: Should be set up so that larger values are suggestive of the alternative hypothesis.\n",
    "- Example: \"The coin is biased towards tails\", $1 - p_{h}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Can't prove a null\n",
    "\n",
    "- If our observed data is far from the expected, suggests null is false\n",
    "- If our observed data is close to expected, does it prove the null?\n",
    "- No! Because the null is very, very specific.\n",
    "    - Coin is *exactly* fair.\n",
    "- Can't distinguish between null and a model very, very similar to null.\n",
    "    - Coin could be biased towards heads with probability 50.000000000001%\n",
    "    - (In reality, coin flips aren't 50/50. They are [closer to 51/49](https://www.smithsonianmag.com/science-nature/gamblers-take-note-the-odds-in-a-coin-flip-arent-quite-5050-145465423/), biased towards whichever side started facing up)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: TA's Dilemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### The Problem\n",
    "\n",
    "* Large Statistics class divided into 12 discussion sections\n",
    "* TAs lead the sections\n",
    "\n",
    "* After the midterm, students in Section 3 notice that the average score in their section is lower than in others.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The TA's Defense\n",
    "\n",
    "TA’s position (Null Hypothesis):\n",
    "* If we had picked my section at random from the whole class, we could observe an average score like this one.\n",
    "\n",
    "Alternative:\n",
    "* No, the average score is too low. Randomness is not the only reason for the low scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv('data/scores_by_section.csv')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What are the observed characteristics of section 3?\n",
    "* Size of section? (`section_size`)\n",
    "* Average of section? (`observed_avg`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_size = scores.loc[scores['Section'] == 3].shape[0]\n",
    "section_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_avg = scores.loc[scores['Section'] == 3, 'Midterm'].mean()\n",
    "observed_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simulating the null hypothesis\n",
    "* Null: \"The 27 scores in my section were drawn uniformly from the 359 scores in the class.\"\n",
    "    - That is, they weren't drawn from some distribution special to me that has lower scores.\n",
    "    - That is, an average this low isn't rare if you repeatedly form groups of 27 students.\n",
    "* Probability Model: Sample uniformly (w/o replacement) 27 students from the class.\n",
    "    - The (class) score distribution is fixed! We are randomly forming sections from the existing class!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discussion Question\n",
    "\n",
    "- Should we use an unsigned or signed test statistic?\n",
    "- What test statistic should we use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Use a signed statistic, since the alternative is that the average in this section is *lower* than you'd expect.\n",
    "* Statistic: Calculate the average midterm score of each \"random\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_trials =  5000\n",
    "averages = []\n",
    "\n",
    "for i in np.arange(N_trials):\n",
    "    random_sample = scores.sample(int(section_size), replace=False)\n",
    "    new_average = np.mean(random_sample['Midterm'])\n",
    "    averages.append(new_average)\n",
    "    \n",
    "averages = np.array(averages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Verdict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(averages, name='Average').plot(\n",
    "    kind='hist', \n",
    "    bins=25,\n",
    "    title='average exam scores from randomly created sections'\n",
    ")\n",
    "plt.scatter(observed_avg, 0, color='red', s=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Not as obvious as previous examples!\n",
    "* Need a concept to capture the uncertainty of the conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Question\n",
    "* What is the probability that under the Null Hypothesis, a result *at least* as extreme as our observation holds?\n",
    "* This quantity is called a **p-value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/20 worse than section 3 did\n",
    "np.count_nonzero(averages <= observed_avg) / N_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(averages, name='Average').plot(\n",
    "    kind='hist', \n",
    "    bins=25,\n",
    "    title='average exam scores from randomly created sections',\n",
    "    density=True\n",
    ")\n",
    "plt.scatter(observed_avg, 0, color='red', s=40);\n",
    "\n",
    "plt.plot([13.6, 13.6], [0, 0.35], color='gold', lw=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Speeding up the TA's dilemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_distr = scores['Midterm'].value_counts(normalize=True)\n",
    "samps = np.random.choice(\n",
    "    cat_distr.index, \n",
    "    p=cat_distr, \n",
    "    size=(50000, int(section_size))\n",
    ")\n",
    "samps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = samps.mean(axis=1)\n",
    "averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(averages, name='Average').plot(\n",
    "    kind='hist', \n",
    "    bins=25,\n",
    "    title='average exam scores from randomly created sections',\n",
    "    density=True\n",
    ")\n",
    "plt.scatter(observed_avg, 0, color='red', s=40);\n",
    "\n",
    "plt.plot([13.6, 13.6], [0, 0.35], color='gold', lw=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistical Significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### Conventions About Inconsistency\n",
    "\n",
    "* **“Inconsistent”**: The test statistic is in the tail of the empirical distribution under the null hypothesis\n",
    "\n",
    "* **“In the tail,” first convention**:\n",
    "    - The area in the tail is less than 5%\n",
    "    - The result is “statistically significant”\n",
    "\n",
    "* **“In the tail,” second convention**:\n",
    "    - The area in the tail is less than 1%\n",
    "    - The result is “highly statistically significant”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Definition of the P-value\n",
    "\n",
    "Formal name: **observed significance level**\n",
    "\n",
    "The P-value is the chance, under the null hypothesis, that the test statistic is equal to the value that was observed in the data or is even further in the direction of the alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## An Error Probability\n",
    "\n",
    "The cutoff for the P-value is an error probability.\n",
    "\n",
    "* If:\n",
    "    - your cutoff is 5%\n",
    "    - and the null hypothesis happens to be true\n",
    "\n",
    "* then there is about a 5% chance that your test will reject the null hypothesis.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
