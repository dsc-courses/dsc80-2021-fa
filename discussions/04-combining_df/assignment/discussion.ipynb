{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"discussion.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion 4\n",
    "\n",
    "### Due Saturday October 23, 11:59:59PM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for formatting purposes\n",
    "def multi_table(table_list):\n",
    "    ''' Acceps a list of IpyTable objects and returns a table which contains each IpyTable in a cell\n",
    "    '''\n",
    "    return HTML(\n",
    "        '<table><tr style=\"background-color:white;\">' + \n",
    "        ''.join(['<td>' + table._repr_html_() + '</td>' for table in table_list]) +\n",
    "        '</tr></table>'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discussion import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review: Combining DataFrames \n",
    "\n",
    "#### `merge()`\n",
    "\n",
    "* Used to combine two (or more) dataframes on the basis of **values of common columns** (indices can also be used, use `left_index=True` and/or `right_index=True`).\n",
    "    * If we are joining columns on columns, the DataFrame indexes will be ignored. \n",
    "    * If we are joining indexes on indexes or indexes on a column or columns, the index will be passed on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left dataframe\n",
    "left = pd.DataFrame({\n",
    "   'id':[1,2,3,4,5],\n",
    "   'Name': ['Aaron', 'Marina', 'Justin', 'Janine', 'Ilya'],\n",
    "   'subject_id':['sub1','sub2','sub4','sub6','sub5']})\n",
    "\n",
    "# right dataframe\n",
    "right = pd.DataFrame(\n",
    "   {'id':[1,2,3,4,5],\n",
    "   'Name': ['Enrique', 'Parker', 'Erik', 'Allston', 'Betty'],\n",
    "   'subject_id':['sub2','sub4','sub3','sub6','sub5']})\n",
    "\n",
    "multi_table([left, right])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`on`**: column or index level names to join on. \n",
    "    * These must be found in both DataFrames. \n",
    "    * If `on` is `None` and not merging on indexes then this defaults to the intersection of the columns in both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge left and right tables on 'id' column\n",
    "on_id = pd.merge(left,right,on='id')\n",
    "\n",
    "# how many rows, how many columns?\n",
    "multi_table([left, right, on_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge left and right tables on 'id' and 'subject_id' columns\n",
    "on_id_subject = pd.merge(left,right,on=['id', 'subject_id'])\n",
    "\n",
    "# how many rows, how many columns, what are the indices?\n",
    "multi_table([left, right, on_id_subject])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`how`**: specifies how to determine which keys are to be included in the resulting table. \n",
    "    * If a key (column name) combination does not appear in either the left or the right tables, the values in the joined table will be `np.NaN`.\n",
    "    * Defaults to `inner`, joining will be performed on index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a = {\n",
    "        'subject_id': ['1', '2', '3', '4', '5'],\n",
    "        'first_name': ['Manny', 'Will', 'Hunter', 'Ian', 'Eric'], \n",
    "        'last_name': ['Machado', 'Myers', 'Renfroe', 'Kinsler', 'Hosmer']}\n",
    "df_a = pd.DataFrame(data_a, columns = ['subject_id', 'first_name', 'last_name'])\n",
    "\n",
    "data_b = {\n",
    "        'subject_id': ['4', '5', '6', '7', '8'],\n",
    "        'first_name': ['Cody', 'Justin', 'Corey', 'Clayton', 'Kenley'], \n",
    "        'last_name': ['Bellinger', 'Turner', 'Seager', 'Kershaw', 'Jansen']}\n",
    "df_b = pd.DataFrame(data_b, columns = ['subject_id', 'first_name', 'last_name'])\n",
    "\n",
    "multi_table([df_a, df_b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Merge Method  | Description                  |\n",
    "| :-------      | :---------------------------:| \n",
    "| `left`        | Use keys from left object    | \n",
    "| `right`       | Use keys from right object   | \n",
    "| `outer`       | Use union of keys            |\n",
    "| `inner`       | Use intersection of keys     | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the output below, what 'how' argument was passed into pd.merge?\n",
    "how_list = ['outer', 'inner', 'right', 'left']\n",
    "\n",
    "merge_method = np.random.choice(how_list)\n",
    "\n",
    "pd.merge(df_a, df_b, on='subject_id', how=merge_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check!\n",
    "merge_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `concat()`\n",
    "\n",
    "* Used to append one (or more) dataframes one below the other (or sideways, depending on whether the axis option is set to 0 or 1).\n",
    "    * Useful if we have two or more data sets containing the same columns but different rows of data.\n",
    "    * We can also the columns from one `Dataframe` to those of another `Dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 'left' below 'right'\n",
    "pd.concat([right, left])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to keep track of the names dataframes after concat, use 'keys'\n",
    "pd.concat([right, left], keys=['right', 'left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 'left' to the side of 'right'\n",
    "pd.concat([right, left], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `join()`\n",
    "\n",
    "* Used to merge two dataframes on the basis of the index; instead of using `merge()` with the option `left_index=True` we can use `join()`.\n",
    "    * Join operation honors the object on which it is called: `a.join(b)` $ \\neq $ `b.join(a)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/join_types.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Inner Join** – default behavior, only keep rows where the merge “on” value exists in both the left and right dataframes.\n",
    "2. **Left Outer** – keep every row in the left dataframe.\n",
    "    * Where there are missing values of the “on” variable in the right dataframe, add `np.NaN` values in the result.\n",
    "3. **Right Join** – keep every row in the right dataframe. \n",
    "    * Where there are missing values of the “on” variable in the left column, add `np.NaN` values in the result.\n",
    "4. **Outer Join** – returns all the rows from the left dataframe, all the rows from the right dataframe, and matches up rows where possible, with `NaNs` elsewhere.\n",
    "\n",
    "We'll start with a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key': ['foo', 'bar'], 'val': [1, 2]}).set_index('key')\n",
    "right = pd.DataFrame({'key': ['foo', 'bar'], 'val': [4, 5]}).set_index('key')\n",
    "\n",
    "joined = left.join(right, lsuffix='_l', rsuffix='_r')\n",
    "\n",
    "multi_table([left, right, joined])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try something a bit more complex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_data = {\n",
    "    'Year' : [2014, 2014, 2014, 2014, 2014],\n",
    "    'Week' : ['A', 'B', 'B', 'C', 'D'],\n",
    "    'Color' : ['Red', 'Red', 'Black', 'Red', 'Green'],\n",
    "    'Val' : [50, 60, 70, 10, 20]\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(df1_data).set_index('Week')\n",
    "\n",
    "df2_data = {\n",
    "    'Year' : [2014, 2014, 2014, 2014, 2014],\n",
    "    'Week' : ['A', 'B', 'C', 'C', 'D'],\n",
    "    'Color' : ['Black', 'Black', 'Green', 'Red', 'Red'],\n",
    "    'Score' : [30, 100, 50, 20, 40]\n",
    "}\n",
    "\n",
    "df2 = pd.DataFrame(df2_data).set_index('Week')\n",
    "\n",
    "multi_table([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many rows, how many columns?\n",
    "df1.join(df2, lsuffix='_l', rsuffix = '_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will this be any different?\n",
    "df2.join(df1, lsuffix='_l', rsuffix = '_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Practice Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "You are given two seperate dataframes: `mlb_2017` and `mlb_2018`. Both dataframes contain statistics for the 2017 and 2018 baseball seasons respectively. Your job is two combine these two dataframes into one using the following guidelines:\n",
    "\n",
    "* The dataframe you return should be indexed by team name (`Tm`).\n",
    "* The dataframe you return should include all columns from both `mlb_2017` and `mlb_2018`.\n",
    "* Use the suffixes `_2017` and `_2018` to differentiate between statistics from both seasons.\n",
    "\n",
    "Create a function `combined_seasons` that returns, as a tuple, the following:\n",
    "\n",
    "* The combined dataframe described above.\n",
    "* The team with most homeruns (`HR`) bewteen the 2017 and 2018 seasons combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the following .txt files\n",
    "mlb_2017 = pd.read_csv(os.path.join('data','mlb_2017.txt'))\n",
    "mlb_2018 = pd.read_csv(os.path.join('data','mlb_2018.txt'))\n",
    "\n",
    "multi_table([mlb_2017.head(), mlb_2018.head()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "mlb_2017 = pd.read_csv(os.path.join('data','mlb_2017.txt'))\n",
    "mlb_2018 = pd.read_csv(os.path.join('data','mlb_2018.txt'))\n",
    "q1_out = combined_seasons(mlb_2017, mlb_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Using the same two dataframes, `mlb_2017` and `mlb_2018`, create a function `seasonal_average` that combines them and takes the mean of each column for each team. \n",
    "\n",
    "* The dataframe you return should be indexed by team name (`Tm`).\n",
    "* Each column should contain the average value between the *2017* and *2018* seasons for the given statistic for each team.\n",
    "    * For example, the `HR` column should contain the average value for `HR` for each team between the *2017* and *2018* seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "mlb_2017 = pd.read_csv(os.path.join('data','mlb_2017.txt'))\n",
    "mlb_2018 = pd.read_csv(os.path.join('data','mlb_2018.txt'))\n",
    "q2_out = seasonal_average(mlb_2017, mlb_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done!\n",
    "\n",
    "* Submit your `.py` file to Gradescope. Note that you only need to submit the `.py` file; this notebook should not be uploaded. Make sure that all of your work is in the `.py` file and not here by running the doctests: `python -m doctest discussion.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q1_out[0].shape == (30, 56)\nTrue",
         "failure_message": "doctest: shape",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q1_out[1] in q1_out[0].index\nTrue",
         "failure_message": "doctest: index",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> all([(('_2017' in x) or ('_2018' in x)) for x in q1_out[0]])\nTrue",
         "failure_message": "doctest: columns",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> q1_out[1] == 'NYY'\nTrue",
         "failure_message": "doctest: most homruns incorrect",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q2_out.shape == (30, 28)\nTrue",
         "failure_message": "doctest: shape",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q2_out.index.nunique() == 30\nTrue",
         "failure_message": "doctest: index",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q2_out.loc['MIN']['HR'] == 186\nTrue",
         "failure_message": "doctest: MIN HR",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q2_out.loc['OAK'].max() == 6190.5\nTrue",
         "failure_message": "doctest: OAK row",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
